{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is for a residual neural network. We sourced a lot of our codebase from here: https://github.com/raghakot/keras-resnet. This implementation was derived from this famous paper: https://arxiv.org/abs/1512.03385."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code contains helper functions which create the resnet. Full disclosure - this code was entirely copy-pasted from github (resnet.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next segment is entirely original. It moves our input data into tensors that can be passed through the keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Finished reading dev set\n",
      "Finished reading test set\n",
      "Finished reading train set\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_HEIGHT = IMAGE_WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "def path_to(dataset, imagenum):\n",
    "    return \"../CS230 Project/\" + dataset + \"_img/img{}.jpg\".format(imagenum)\n",
    "\n",
    "def load_data():\n",
    "    print(\"Starting\")\n",
    "    with open('labels.json') as f_labels:\n",
    "        labels = json.load(f_labels)\n",
    "        y_train = np.expand_dims(np.asarray(labels[\"trainY\"]), axis = 1)\n",
    "        y_dev = np.expand_dims(np.asarray(labels[\"devY\"]), axis = 1)\n",
    "        y_test = np.expand_dims(np.asarray(labels[\"testY\"]), axis = 1)\n",
    "        # X Dev\n",
    "        X_dev = np.zeros((len(labels[\"devX\"]), IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "        for imagenum in range(len(labels[\"devX\"])):\n",
    "            im_arr = cv2.imread(path_to(\"dev\", imagenum))\n",
    "            X_dev[imagenum,:,:,:] = im_arr\n",
    "        print(\"Finished reading dev set\")\n",
    "        # X Test\n",
    "        X_test = np.zeros((len(labels[\"testX\"]), IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "        for imagenum in range(len(labels[\"testX\"])):\n",
    "            im_arr = cv2.imread(path_to(\"test\", imagenum))\n",
    "            X_test[imagenum,:,:,:] = im_arr\n",
    "        print(\"Finished reading test set\")\n",
    "        # X Train\n",
    "        X_train = np.zeros((len(labels[\"trainX\"]), IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\n",
    "        for imagenum in range(len(labels[\"trainX\"])):\n",
    "            im_arr = cv2.imread(path_to(\"train\", imagenum))\n",
    "            X_train[imagenum,:,:,:] = im_arr\n",
    "        print(\"Finished reading train set\")\n",
    "    return (X_train, y_train), (X_dev, y_dev), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_dev, y_dev), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this segment contains the code for the network itself. It consists of a modified implementation of the \"cifiar10.py\" script from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67938 samples, validate on 8492 samples\n",
      "Epoch 1/200\n",
      "67938/67938 [==============================] - 846s 12ms/step - loss: 2.5785 - acc: 0.1815 - val_loss: 2.4398 - val_acc: 0.1855\n",
      "Epoch 2/200\n",
      "67938/67938 [==============================] - 844s 12ms/step - loss: 2.3253 - acc: 0.2066 - val_loss: 2.4872 - val_acc: 0.1684\n",
      "Epoch 3/200\n",
      "67938/67938 [==============================] - 845s 12ms/step - loss: 2.2136 - acc: 0.2185 - val_loss: 2.2296 - val_acc: 0.1954\n",
      "Epoch 4/200\n",
      "67938/67938 [==============================] - 841s 12ms/step - loss: 2.1493 - acc: 0.2270 - val_loss: 2.2455 - val_acc: 0.1972\n",
      "Epoch 5/200\n",
      "67938/67938 [==============================] - 836s 12ms/step - loss: 2.1084 - acc: 0.2358 - val_loss: 2.1423 - val_acc: 0.2150\n",
      "Epoch 6/200\n",
      "67938/67938 [==============================] - 840s 12ms/step - loss: 2.0782 - acc: 0.2464 - val_loss: 2.1416 - val_acc: 0.2085\n",
      "Epoch 7/200\n",
      "67938/67938 [==============================] - 842s 12ms/step - loss: 2.0532 - acc: 0.2560 - val_loss: 2.2522 - val_acc: 0.1972\n",
      "Epoch 8/200\n",
      "67938/67938 [==============================] - 837s 12ms/step - loss: 2.0337 - acc: 0.2662 - val_loss: 2.1580 - val_acc: 0.2068\n",
      "Epoch 9/200\n",
      "67938/67938 [==============================] - 837s 12ms/step - loss: 2.0118 - acc: 0.2829 - val_loss: 2.2111 - val_acc: 0.2110\n",
      "Epoch 10/200\n",
      "67938/67938 [==============================] - 837s 12ms/step - loss: 1.9797 - acc: 0.3024 - val_loss: 2.1998 - val_acc: 0.2184\n",
      "Epoch 11/200\n",
      "67938/67938 [==============================] - 839s 12ms/step - loss: 1.9402 - acc: 0.3268 - val_loss: 2.2654 - val_acc: 0.2056\n",
      "Epoch 12/200\n",
      "67938/67938 [==============================] - 837s 12ms/step - loss: 1.6864 - acc: 0.4387 - val_loss: 2.3657 - val_acc: 0.2102\n",
      "Epoch 13/200\n",
      "67938/67938 [==============================] - 838s 12ms/step - loss: 1.4848 - acc: 0.5177 - val_loss: 2.5840 - val_acc: 0.2114\n",
      "Epoch 14/200\n",
      "67938/67938 [==============================] - 834s 12ms/step - loss: 1.2690 - acc: 0.6054 - val_loss: 2.9163 - val_acc: 0.2005\n",
      "Epoch 15/200\n",
      "67938/67938 [==============================] - 839s 12ms/step - loss: 1.0424 - acc: 0.6908 - val_loss: 3.4453 - val_acc: 0.2058\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on our small images dataset.\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('resnet18_deepconnotation.csv')\n",
    "\n",
    "batch_size = 200\n",
    "nb_classes = 8\n",
    "nb_epoch = 200\n",
    "data_augmentation = False\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# The images are RGB.\n",
    "img_channels = 3\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_dev = np_utils.to_categorical(y_dev, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_dev = X_dev.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_dev -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128. #128 = 256 / 2\n",
    "X_dev /= 128.\n",
    "X_test /= 128.\n",
    "\n",
    "#Code to shrink dataset, should not be used for serious training\n",
    "#X_train = X_train[:1000,:,:,:]\n",
    "#X_dev = X_dev[:1000,:,:,:]\n",
    "#X_test = X_test[:1000,:,:,:]\n",
    "#Y_train = Y_train[:1000,:]\n",
    "#Y_dev = Y_dev[:1000,:]\n",
    "#Y_test = Y_test[:1000,:]\n",
    "\n",
    "model = ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_dev, Y_dev),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_dev, Y_dev),\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"full_train_1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
