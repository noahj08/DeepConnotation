{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathe\\Anaconda3\\envs\\CS230 Project\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medium_show_and_tell_caption_generator\n",
    "from medium_show_and_tell_caption_generator import inference\n",
    "from medium_show_and_tell_caption_generator import caption_generator\n",
    "from medium_show_and_tell_caption_generator import model\n",
    "from medium_show_and_tell_caption_generator import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNum = 67938\n",
    "\n",
    "input_files_=[]\n",
    "input_ = r'D:\\CS230 Project\\train_img\\img'\n",
    "for i in range (trainNum):\n",
    "    input_files_.append(input_+str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished imgs[15500, 15600]/67938\n",
      "\n",
      "finished imgs[15600, 15700]/67938\n",
      "\n",
      "finished imgs[15700, 15800]/67938\n",
      "\n",
      "finished imgs[15800, 15900]/67938\n",
      "\n",
      "finished imgs[15900, 16000]/67938\n",
      "\n",
      "finished imgs[16000, 16100]/67938\n",
      "\n",
      "finished imgs[16100, 16200]/67938\n",
      "\n",
      "finished imgs[16200, 16300]/67938\n",
      "\n",
      "finished imgs[16300, 16400]/67938\n",
      "\n",
      "finished imgs[16400, 16500]/67938\n",
      "\n",
      "finished imgs[16500, 16600]/67938\n",
      "\n",
      "finished imgs[16600, 16700]/67938\n",
      "\n",
      "finished imgs[16700, 16800]/67938\n",
      "\n",
      "finished imgs[16800, 16900]/67938\n",
      "\n",
      "finished imgs[16900, 17000]/67938\n",
      "\n",
      "finished imgs[17000, 17100]/67938\n",
      "\n",
      "finished imgs[17100, 17200]/67938\n",
      "\n",
      "finished imgs[17200, 17300]/67938\n",
      "\n",
      "finished imgs[17300, 17400]/67938\n",
      "\n",
      "finished imgs[17400, 17500]/67938\n",
      "\n",
      "finished imgs[17500, 17600]/67938\n",
      "\n",
      "finished imgs[17600, 17700]/67938\n",
      "\n",
      "finished imgs[17700, 17800]/67938\n",
      "\n",
      "finished imgs[17800, 17900]/67938\n",
      "\n",
      "finished imgs[17900, 18000]/67938\n",
      "\n",
      "finished imgs[18000, 18100]/67938\n",
      "\n",
      "finished imgs[18100, 18200]/67938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skip=15500\n",
    "block_size = 100\n",
    "num_iter_train = (trainNum+skip)//block_size\n",
    "remainder_train = trainNum%block_size\n",
    "\n",
    "\n",
    "# #run blocks of captioning\n",
    "with open('train_enc2.json') as json_data:\n",
    "    encodings_train=np.asarray(json.load(json_data))\n",
    "    \n",
    "for i in range(num_iter_train):\n",
    "    start_train =skip +i*block_size \n",
    "    end_train =skip +i*block_size +block_size\n",
    "    encodings_train = np.vstack((encodings_train,inference.main(input_files_[start_train:end_train])))\n",
    "    with open('train_enc3.json', 'w') as outfile:\n",
    "        json.dump(encodings_train.tolist(),outfile)\n",
    "    print(\"finished imgs[%d, %d]/%d\\n\" % (start_train, end_train, trainNum))\n",
    "\n",
    "#finish remainder of captioning\n",
    "start_train = trainNum - trainNum%block_size\n",
    "end_train =trainNum\n",
    "encodings_train = np.vstack((encodings_train,inference.main(input_files_[start_train:end_train])))\n",
    "\n",
    "with open('train_enc3.json', 'w') as outfile:\n",
    "        json.dump(encodings_train.tolist(),outfile)\n",
    "print(\"finished imgs[%d, %d]/%d\\n\" % (start_train, end_train, trainNum))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_enc1.json') as json_data:\n",
    "    d = json.load(json_data)\n",
    "arr=(np.array(d)).T\n",
    "arr.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
